{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/7fqxn4216jl8m88cxmwr0rdh0000gn/T/ipykernel_71053/224033482.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MaxTemperature</th>\n",
       "      <th>MinTemperature</th>\n",
       "      <th>AvgTemperature</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>10.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>11.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date MaxTemperature MinTemperature AvgTemperature Precipitation  \\\n",
       "0    2014-01-01            8.7           -1.8            2.9           0.0   \n",
       "1    2014-01-02            4.0           -1.1            0.8           5.5   \n",
       "2    2014-01-03           -0.7           -9.5           -6.4           0.0   \n",
       "3    2014-01-04            1.0           -9.8           -4.5           0.0   \n",
       "4    2014-01-05            5.6           -1.3            1.4          14.5   \n",
       "...         ...            ...            ...            ...           ...   \n",
       "3647 2023-12-27           10.3            7.0            8.8          12.1   \n",
       "3648 2023-12-28           11.9            5.9            9.5           0.0   \n",
       "3649 2023-12-29            7.5            2.6            5.2           1.6   \n",
       "3650 2023-12-30            8.0            2.0            4.1           0.0   \n",
       "3651 2023-12-31            8.8            1.2            4.9           0.0   \n",
       "\n",
       "      Year  \n",
       "0     2014  \n",
       "1     2014  \n",
       "2     2014  \n",
       "3     2014  \n",
       "4     2014  \n",
       "...    ...  \n",
       "3647  2023  \n",
       "3648  2023  \n",
       "3649  2023  \n",
       "3650  2023  \n",
       "3651  2023  \n",
       "\n",
       "[3630 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data \n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"weather_data.csv\")\n",
    "\n",
    "# Rename the columns\n",
    "data = data.rename(columns={\n",
    "    'LST_DATE': 'Date',\n",
    "    'T_DAILY_MAX': 'MaxTemperature',\n",
    "    'T_DAILY_MIN': 'MinTemperature',\n",
    "    'T_DAILY_AVG': 'AvgTemperature',\n",
    "    'P_DAILY_CALC': 'Precipitation'\n",
    "})\n",
    "# Remove the unnamed column\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# # Convert the date column to datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'], format= '%Y%m%d')\n",
    "data['Year'] = data['Date'].dt.year\n",
    "\n",
    "# Replace all occurrences of -9999 with NaN\n",
    "data.replace(-9999, pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming `df` is your DataFrame and it has a column 'avg_temp' for average temperatures\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAvgTemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Normalize the data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Assuming `df` is your DataFrame and it has a column 'avg_temp' for average temperatures\n",
    "data = data['AvgTemperature'].values.reshape(-1,1)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Splitting dataset into training (first 9 years) and testing data (last year)\n",
    "train_size = int(len(data) * 0.9)\n",
    "test_size = len(data) - train_size\n",
    "train, test = data[0:train_size, :], data[train_size:len(data), :]\n",
    "\n",
    "# Convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 30\n",
    "X_train, Y_train = create_dataset(train, look_back)\n",
    "X_test, Y_test = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# Making predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Invert predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "Y_train = scaler.inverse_transform([Y_train])\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "# Plotting\n",
    "trainPredictPlot = np.empty_like(data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "\n",
    "testPredictPlot = np.empty_like(data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(data)-1, :] = test_predict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(data))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n",
    "# Predicting 50 years into the\n",
    "\n",
    "# Assuming each year has roughly 365.25 days on average (accounting for leap years)\n",
    "days_in_future = 50 * 365.25\n",
    "future_predictions = test_predict[-1].reshape(1, 1, look_back)  # Start prediction from the last test data point\n",
    "\n",
    "# Generating future data points\n",
    "future_values = []\n",
    "for i in range(int(days_in_future)):\n",
    "    prediction = model.predict(future_predictions)\n",
    "    future_predictions = np.append(future_predictions[:, :, 1:], prediction.reshape(1, 1, 1), axis=2)\n",
    "    future_values.append(prediction)\n",
    "\n",
    "# Reshape future values for inverse transformation\n",
    "future_values = np.array(future_values).reshape(-1, 1)\n",
    "future_values = scaler.inverse_transform(future_values)\n",
    "\n",
    "# Plotting future predictions\n",
    "plt.plot(range(len(data)), scaler.inverse_transform(data), label=\"Historical Data\")\n",
    "plt.plot(range(len(data), len(data) + len(future_values)), future_values, label=\"Future Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
